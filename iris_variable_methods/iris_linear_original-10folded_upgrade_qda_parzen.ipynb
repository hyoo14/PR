{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from scipy import linalg\n",
    "import sklearn.discriminant_analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KernelDensity as parzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    f=open(\"iris(150).csv\", 'r')\n",
    "    lines=[line.strip() for line in f.readlines()]\n",
    "    f.close()\n",
    "    \n",
    "    lines=[line.split(\",\") for line in lines if line]\n",
    "    #print('cool guy', lines)\n",
    "    lines = lines[1:]\n",
    "    #print(lines)\n",
    "    #print([line[:6] for line in lines if line])\n",
    "    \n",
    "        \n",
    "    data=np.array([line[1:5] for line in lines if line], dtype=np.float)\n",
    "    \n",
    "    class1=np.array([line[1:5] for line in lines if line[-1]==\"setosa\"], dtype=np.float)\n",
    "    \n",
    "    class2=np.array([line[1:5] for line in lines if line[-1]==\"virginica\"], dtype=np.float)\n",
    "    \n",
    "    class3=np.array([line[1:5] for line in lines if line[-1]==\"versicolor\"], dtype=np.float)\n",
    "    \n",
    "    #list of class labels\n",
    "    labels=[]\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        strt=line.pop()\n",
    "        #print(strt)\n",
    "        labels.append(strt)\n",
    "    \n",
    "    #print(labels)\n",
    "    #create array of labels\n",
    "    labels=[line.split(\",\") for line in labels if line]\n",
    "    t=np.zeros(shape=(150, 3))\n",
    "    t_n = np.zeros(shape=(150,1))\n",
    "    #create target vector encoded according to 1-of-K scheme\n",
    "    for i in range(len(data)):\n",
    "        if labels[i]==[\"setosa\"]: \n",
    "            t[i][0]=1\n",
    "            t_n[i] = 0\n",
    "        elif labels[i]==[\"versicolor\"]: \n",
    "            t[i][1]=1\n",
    "            t_n[i] = 1\n",
    "        elif labels[i]==[\"virginica\"]: \n",
    "            t[i][2]=1\n",
    "            t_n[i] = 2\n",
    "    \n",
    "    return class1, class2, class3, data, t, t_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(x, mean, cov):\n",
    "    xm=np.reshape((x-mean), (-1, 1))\n",
    "    px=1/(math.pow(2.0*math.pi, 2))*1/math.sqrt(np.linalg.det(cov))*math.exp(-(np.dot(np.dot(xm.T, np.linalg.inv(cov)), xm))/2)\n",
    "    return px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.73429132  9.73429132  9.73429132  9.73429132  9.73429132  9.73429132\n",
      "  9.73429132  9.73429132  9.73429132  9.73429132  9.73429132  9.73429132\n",
      "  9.73429132  9.73429132  9.73429132]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    class1, class2, class3, data, t, t_n=read_data()\n",
    "\n",
    "    count=np.zeros(shape=(150,1))\n",
    "    t_assigned=np.zeros(shape=(150, 3))\n",
    "    cov=np.zeros(shape=(3, 4, 4))\n",
    "    mean=np.zeros(shape=(3, 4))\n",
    "\n",
    "    #compute means for each class\n",
    "    mean1=class1.mean(axis=0)\n",
    "    mean2=class2.mean(axis=0)\n",
    "    mean3=class3.mean(axis=0)\n",
    "    #compute covariance matrices, such that the columns are variables and rows are observations of variables\n",
    "    cov1=np.cov(class1, rowvar=0)\n",
    "    cov2=np.cov(class2, rowvar=0)\n",
    "    cov3=np.cov(class3, rowvar=0)\n",
    "    \n",
    "    #compute gaussian likelihood functions p(x|Ck) for each class\n",
    "    for i in range(135, 150):\n",
    "        px1=(1/3.0)*gaussian(data[i], mean1, cov1)\n",
    "        px2=(1/3.0)*gaussian(data[i], mean2, cov2)\n",
    "        px3=(1/3.0)*gaussian(data[i], mean3, cov3)\n",
    "        m=np.max([px1, px2, px3])\n",
    "    #compute posterior probability p(Ck|x) assuming that p(x|Ck) is gaussian and the entire expression is wrapped by sigmoid function \n",
    "        pc1=((math.exp(px1)*math.exp(-m))*math.exp(m))/((math.exp(px2)*math.exp(-m)+math.exp(px3)*math.exp(-m))*math.exp(m))\n",
    "        pc2=((math.exp(px2)*math.exp(-m))*math.exp(m))/((math.exp(px1)*math.exp(-m)+math.exp(px3)*math.exp(-m))*math.exp(m))\n",
    "        pc3=((math.exp(px3)*math.exp(-m))*math.exp(m))/((math.exp(px1)*math.exp(-m)+math.exp(px2)*math.exp(-m))*math.exp(m))\n",
    "        #assign p(Ck|x)=1 if p(Ck|x)>>p(Cj|x) for all j!=k\n",
    "        if pc1>pc2 and pc1>pc3: t_assigned[i][0]=1\n",
    "        elif pc3>pc1 and pc3>pc2: t_assigned[i][1]=1\n",
    "        elif pc2>pc1 and pc2>pc3: t_assigned[i][2]=1\n",
    "    #count the number of misclassifications\n",
    "        for j in range(3):\n",
    "            if t[i][j]-t_assigned[i][j]!=0: count[i]=1\n",
    "\n",
    "    cov=[cov1, cov2, cov3]\n",
    "    mean=[mean1, mean2, mean3]\n",
    "\n",
    "    t1=np.zeros(shape=(len(class1), 1))\n",
    "    t2=np.zeros(shape=(len(class2), 1))\n",
    "    t3=np.zeros(shape=(len(class3), 1))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(class1)):\n",
    "            if t_assigned[i][0]==1: t1[j]=1\n",
    "            elif t_assigned[i][1]==1: t2[j]=2\n",
    "            elif t_assigned[i][2]==1: t3[j]=3\n",
    "\n",
    "\n",
    "    #print (\"number of misclassifications\", sum(count) )#, \"assigned labels to data points\", t_assigned, \"target data\", t)\n",
    "    \n",
    "    \"\"\"\n",
    "    #print(t)\n",
    "    qda = QDA(store_covariances=True)\n",
    "    #qda = LDA(store_covariances=True)\n",
    "    start = 0\n",
    "    end = 15\n",
    "    y_pred = qda.fit(data, t_n).predict(data[start:end])\n",
    "    cnt = 0\n",
    "    for i in range(15):\n",
    "        if y_pred[i] != t_n[start+i][0]:\n",
    "            cnt+=1\n",
    "    #print(cnt)\n",
    "    \n",
    "    #print(t)\n",
    "    qda = QDA(store_covariances=True)\n",
    "    #qda = LDA(store_covariances=True)\n",
    "    start = 0\n",
    "    end = 15\n",
    "    y_pred = qda.fit(data, t_n).predict(data[start:end])\n",
    "    cnt = 0\n",
    "    for i in range(15):\n",
    "        if y_pred[i] != t_n[start+i][0]:\n",
    "            cnt+=1\n",
    "    #print(cnt)\n",
    "    \"\"\"\n",
    "    kde = parzen(bandwidth = 0.01, kernel='gaussian')\n",
    "    start = 0\n",
    "    end = 15\n",
    "    y_pred = kde.fit(data, t_n).score_samples(data[start:end]) #.predict(data[start:end])\n",
    "    cnt = 0\n",
    "    \n",
    "    print(y_pred)\n",
    "    \"\"\"for i in range(15):\n",
    "        if y_pred[i] != t_n[start+i][0]:\n",
    "            cnt+=1\n",
    "    print(cnt)\n",
    "\"\"\"\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
